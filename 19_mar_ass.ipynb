{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1eecdd-8947-431d-a490-ec1882ea30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values.\n",
    "Answer-Missing values are common when working with real-world datasets â€“ not the cleaned ones available on Kaggle, \n",
    "for example. Missing data could result from a human factor (for example, a person deliberately failing to respond to a \n",
    "survey question), a problem in electrical sensors, or other factors\n",
    " While working it is essential to handle misisng values beacause it will show many types of error while plotting graph and\n",
    " if we training a model it will affect the accuracy of the model.\n",
    " \n",
    "The k-NN algorithm can ignore a column from a distance measure when a value is missing. Naive Bayes can also support \n",
    "missing values when making a prediction.'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4c8645-322b-4fc5-b957-aa0e139e330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name   Age Gender   Salary\n",
      "0  Alice  25.0      F  50000.0\n",
      "1    Bob  30.0      M  60000.0\n",
      "example of Imputation\n",
      "      Name    Age Gender   Salary\n",
      "0    Alice  25.00      F  50000.0\n",
      "1      Bob  30.00      M  60000.0\n",
      "2  Charlie  28.75      M  55000.0\n",
      "3    David  28.00   None  65000.0\n",
      "4    Emily  32.00      F      NaN\n"
     ]
    }
   ],
   "source": [
    "'''Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "Answer-There are several techniques that can be used to handle missing data. Here are some of them with example code in Python:\n",
    "\n",
    "Deletion: This technique involves removing rows or columns with missing data from the dataset. It can be done in two ways:\n",
    "\n",
    "a. Listwise deletion: Removes all the rows that contain missing values.\n",
    "\n",
    "b. Pairwise deletion: Removes only those rows that contain missing values in a particular column.\n",
    "\n",
    "Here's an example of listwise deletion using Pandas library in Python:'''\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample dataset\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],\n",
    "        'Age': [25, 30, None, 28, 32],\n",
    "        'Gender': ['F', 'M', 'M', None, 'F'],\n",
    "        'Salary': [50000, 60000, 55000, 65000, None]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying listwise deletion\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df)\n",
    "'''2.)Imputation: This technique involves filling in missing values with some estimated values. Some common methods of imputation are:\n",
    "\n",
    "a. Mean imputation: Replaces missing values with the mean of the non-missing values in the column.\n",
    "\n",
    "b. Median imputation: Replaces missing values with the median of the non-missing values in the column.\n",
    "\n",
    "c. Mode imputation: Replaces missing values with the mode (most frequent value) of the non-missing values in the column.\n",
    "\n",
    "Here's an example of mean imputation using Pandas library in Python:'''\n",
    "import pandas as pd\n",
    "\n",
    "# Creating a sample dataset\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emily'],\n",
    "        'Age': [25, 30, None, 28, 32],\n",
    "        'Gender': ['F', 'M', 'M', None, 'F'],\n",
    "        'Salary': [50000, 60000, 55000, 65000, None]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying mean imputation\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "print(\"example of Imputation\")\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21446b9b-5448-41f2-bd55-ab284a3ecf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "Answer-Imbalanced data is a situation where the number of instances belonging to one class in a dataset is significantly\n",
    "higher than the other classes. In other words, the distribution of classes in the dataset is skewed towards one class,\n",
    "resulting in an imbalance in the dataset.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to several issues:\n",
    "\n",
    "1)Biased model: Since the dataset is skewed towards one class, the model will be biased towards that class, \n",
    "resulting in poor performance on the other class.\n",
    "\n",
    "2)Overfitting: The model may overfit on the majority class and may not generalize well on the minority class.\n",
    "\n",
    "3)Misclassification: The model may misclassify instances belonging to the minority class as the majority class, \n",
    "resulting in poor performance on the minority class.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd2156-2521-4d5d-8137-43326f10a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required.\n",
    "Answer-In upsampling we have to produce a new data to make the imbalance dataset as balance data set by using some \n",
    "upsampling technique and in downsampling we reduce the data of that feature that have more data to other feature\n",
    "by using some downsampling techniques.\n",
    "Downsampling reduces dimensionality of the features while losing some information. It saves computation. Upsampling \n",
    "brings back the resolution to the resolution of previous layer.\n",
    "Lets take an example we have to predict the coin head or tail and we have data.\n",
    "In this data we input and output in output feature there 900 head and only 100 tail.\n",
    "If we train that model so this model can be baised to head so what we can do is to we can perform sampling technique.\n",
    "Like we can increase the sample size of tail to 900 that is called upsampling\n",
    "In other hand we can reduce the size of head to 100 that is called downsampling'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc011b88-91e6-477b-9d14-d361247ed6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5: What is data Augmentation? Explain SMOTE.\n",
    "Answer-Data augmentation is a technique used in machine learning and deep learning to artificially increase the size of \n",
    "a training dataset by creating additional examples from the original data. This is done to improve the model's accuracy\n",
    "and generalization by exposing it to more variations of the original data.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used in classification \n",
    "tasks where the dataset is imbalanced. Imbalanced data refers to the situation where one class is under-represented \n",
    "compared to the other classes. This can cause problems in the training of a model as it may result in biased results\n",
    "where the minority class is not well-represented.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c352e2-7e78-47f0-9e43-77ecde951e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "Answer-In statistics, outliers are data points that are significantly different from other data points in a dataset. \n",
    "Outliers can occur due to measurement errors, natural variation, or rare events. They can have a significant impact on\n",
    "the results of statistical analyses, leading to incorrect conclusions. Therefore, it is essential to handle outliers\n",
    "before performing any statistical analysis.\n",
    "\n",
    "Outliers can affect the accuracy of statistical measures such as mean, standard deviation, and correlation coefficient, \n",
    "leading to skewed results. For example, if a dataset contains outliers, the mean value may not be a representative \n",
    "measure of the central tendency of the data. Outliers can also lead to incorrect conclusions about the relationships \n",
    "between variables, which can affect the predictions made by machine learning models.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb74318-7cfb-40c2-bc8f-fa3ec330823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "Answer-First i will analyze the data set if the data set is quiet large in comparison to the number of values that is \n",
    "missing in the dataset then i simply remove them.\n",
    "If the number of missing values is large then i can perform some statistical analysis like meand,mode and median \n",
    "and then i can replace with the appropiate paremeter\n",
    "The two method i can perform Deletion and Imputation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f59e873-16a4-484c-acc5-55f79ee05eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?\n",
    "Answer-Analyze patterns of missing data: Check for patterns in the missing data. If there is a clear pattern, \n",
    "then it is likely that the missing data is not random. For example, missing data may be related to specific demographic \n",
    "variables or time periods.\n",
    "\n",
    "Explore the correlation between missing values and other variables: Analyze the correlation between the variables \n",
    "with missing values and other variables in the dataset. If there is a significant correlation between missing values\n",
    "and certain variables, then the missing data is likely not random.\n",
    "\n",
    "Use statistical tests: Use statistical tests to identify if there is a significant difference between the values of \n",
    "missing data and those of the observed data. If there is a significant difference, then it suggests that the missing data is not random.\n",
    "\n",
    "Use machine learning algorithms: Use machine learning algorithms to classify the data as missing at random or not at \n",
    "random. For example, the classification and regression trees (CART) algorithm can be used to identify patterns in the \n",
    "missing data.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0bb53-a11d-4b1e-8d89-06a9c4c23b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "Answer-Dealing with imbalanced datasets is a common challenge in machine learning projects. Here are some strategies \n",
    "that can be used to evaluate the performance of a machine learning model on an imbalanced dataset:\n",
    "\n",
    "Use appropriate evaluation metrics: Accuracy is not a suitable metric to evaluate performance on an imbalanced dataset. \n",
    "Instead, metrics such as precision, recall, F1-score, and Area Under the ROC Curve (AUC-ROC) should be used. These\n",
    "metrics take into account the imbalance in the dataset and provide a more accurate representation of the model's performance.\n",
    "\n",
    "Use stratified sampling: Stratified sampling can be used to ensure that the proportion of samples in each class is \n",
    "maintained in the training and testing data. This can help to avoid overfitting to the majority class and underfitting \n",
    "to the minority class.\n",
    "\n",
    "Resampling techniques: Resampling techniques such as oversampling and undersampling can be used to balance the dataset. \n",
    "Oversampling involves creating more samples of the minority class, while undersampling involves removing samples from\n",
    "the majority class. Care should be taken when using these techniques as they can result in overfitting or underfitting'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a491dbe-d420-4077-912c-38b72e11219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?\n",
    "Answer-Random under-sampling: This method involves randomly selecting a subset of the majority class to match \n",
    "the number of samples in the minority class. This can be done using the sample function in Python.\n",
    "\n",
    "Cluster-based under-sampling: This method involves clustering the majority class and selecting a representative \n",
    "sample from each cluster. This can be done using the KMeans algorithm in Python.\n",
    "\n",
    "Tomek links: This method involves identifying pairs of samples in the dataset that are closest to each other but \n",
    "belong to different classes. The majority class samples in these pairs are then removed from the dataset. This can \n",
    "be done using the TomekLinks function in Python.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf810f9c-43ec-4303-89f4-c3285dd9f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?\n",
    "Answer-When dealing with imbalanced datasets where the minority class has a low percentage of occurrences, one can \n",
    "use various methods to balance the dataset and up-sample the minority class. Here are some commonly used techniques:\n",
    "\n",
    "Oversampling: Oversampling involves duplicating the minority class data points to balance the dataset. One popular \n",
    "oversampling method is the Synthetic Minority Over-sampling Technique (SMOTE), which generates new synthetic data points\n",
    "by interpolating between existing minority class samples.\n",
    "\n",
    "Undersampling: Undersampling involves removing some data points from the majority class to balance the dataset. This \n",
    "can be done randomly or by selecting data points that are farthest from the minority class data points. However,\n",
    "undersampling can result in a loss of information.\n",
    "\n",
    "Hybrid Methods: Hybrid methods combine oversampling and undersampling techniques to balance the dataset effectively. \n",
    "For example, the SMOTEENN technique combines SMOTE oversampling and Edited Nearest Neighbors (ENN) undersampling.\n",
    "\n",
    "Cost-sensitive learning: Cost-sensitive learning involves assigning different '"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
